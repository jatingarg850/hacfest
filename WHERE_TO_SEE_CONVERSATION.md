# Where to See the Conversation

## Quick Answer

**Backend Console:** Shows agent status only (not conversation)  
**Flutter Console:** Shows audio events (AI speaking, user speaking)  
**Conversation Content:** Not available by default (see workarounds below)

## Backend Console (Node.js)

### What You See âœ…

```
ğŸ™ï¸ Starting Agora AI agent...
âœ… Agent created successfully!
Agent ID: A42AK68EE47AJ78TV66AC64VM56TD28V
Status: RUNNING

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¤ AGENT IS NOW LIVE AND LISTENING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

What happens next:
  1. User speaks â†’ ASR transcribes to text
  2. Text â†’ Gemini LLM processes
  3. Gemini response â†’ ElevenLabs TTS
  4. TTS audio â†’ Plays to user

âš ï¸  NOTE: Conversation content is NOT sent to this backend.
   The dialogue happens directly in the Agora RTC channel.

âœ… Agent is fully operational and ready!

ğŸ’¬ CONVERSATION IS HAPPENING NOW (if user is speaking)
   Check Flutter app logs to see audio state changes
```

### What You DON'T See âŒ

- User speech text
- AI response text
- Conversation history
- Real-time dialogue

## Flutter Console (Dart)

### What You See âœ…

```
ğŸ”„ Reinitializing Agora for clean state...
âœ… Agora RTC Engine initialized successfully
ğŸ“¡ Requesting voice session from backend...
âœ… Backend response received
ğŸ”— Joining Agora channel...
âœ… Successfully joined channel

ğŸ”Š Setting up audio for AI agent...
âœ… USER JOINED EVENT: UID=999
ğŸ”Š Unmuting UID 999 immediately...
âœ… Audio fully enabled for UID 999

ğŸ”Š REMOTE AUDIO STATE CHANGED:
   UID: 999
   State: remoteAudioStateDecoding
   
âœ… AI IS SPEAKING! Audio decoding...

ğŸ”Š Audio detected! Volume: 44
```

### What This Means

- `USER JOINED EVENT: UID=999` â†’ AI agent joined the channel
- `remoteAudioStateDecoding` â†’ AI is speaking
- `Audio detected! Volume: 44` â†’ Audio is playing

## How to See Actual Conversation

### Option 1: Add Flutter Logging (Recommended)

Add this to your Flutter app to log when AI speaks:

```dart
// In voice_provider.dart
onRemoteAudioStateChanged: (connection, remoteUid, state, reason, elapsed) {
  if (state == RemoteAudioState.remoteAudioStateDecoding) {
    debugPrint('ğŸ¤– AI is speaking now!');
    // You could send this to your backend:
    // _api.post('/log-event', { type: 'ai_speaking', timestamp: DateTime.now() });
  }
}
```

### Option 2: Create LLM Proxy (Advanced)

Create a proxy server that logs all LLM requests:

```javascript
// proxy-server.js
app.post('/gemini-proxy', async (req, res) => {
  // Log the request
  console.log('ğŸ‘¤ USER:', req.body.contents[0].parts[0].text);
  
  // Forward to Gemini
  const response = await axios.post(GEMINI_URL, req.body);
  
  // Log the response
  console.log('ğŸ¤– AI:', response.data);
  
  // Return to agent
  res.json(response.data);
});
```

Then update agent config:
```javascript
llm: {
  url: "https://your-proxy.com/gemini-proxy",
  // ...
}
```

**Downside:** Adds latency and complexity

### Option 3: Use Agora Analytics (If Available)

Check if your Agora plan includes conversation analytics:
- Agora Console â†’ Analytics
- May show session metrics
- Usually doesn't include full transcripts

## Recommended Setup

### For Development

**Terminal 1: Backend**
```bash
cd backend
npm start
```
Watch for: Agent status, errors

**Terminal 2: Flutter**
```bash
cd flutter_app
flutter run
```
Watch for: Audio events, user interactions

### For Production

**Track Metrics:**
```javascript
// In your backend
app.post('/api/voice/stop', async (req, res) => {
  const session = await VoiceSession.findById(req.body.sessionId);
  const duration = (Date.now() - session.createdAt) / 1000;
  
  console.log('ğŸ“Š Session Complete:');
  console.log('  User:', session.userId);
  console.log('  Duration:', duration, 'seconds');
  console.log('  Agent ID:', session.agentId);
  
  // Store metrics in database
  await SessionMetrics.create({
    userId: session.userId,
    duration,
    timestamp: new Date()
  });
});
```

## Visual Guide

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER'S DEVICE                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Flutter App (Voice Chat)                â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  ğŸ¤ User speaks                                  â”‚   â”‚
â”‚  â”‚  ğŸ‘‚ Hears AI response                           â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  âœ… CAN SEE: Audio events, state changes        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Agora RTC Channel
                          â”‚ (Real-time audio)
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGORA CONVERSATIONAL AI                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  AI Agent (UID 999)                             â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  1. ASR: Speech â†’ Text                          â”‚   â”‚
â”‚  â”‚  2. LLM: Text â†’ Response (Gemini)               â”‚   â”‚
â”‚  â”‚  3. TTS: Response â†’ Speech (ElevenLabs)         â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  âŒ DOES NOT send conversation to backend       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ REST API
                          â”‚ (Start/Stop only)
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  YOUR BACKEND                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Node.js Server                                 â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  âœ… CAN SEE:                                     â”‚   â”‚
â”‚  â”‚    - Agent started                              â”‚   â”‚
â”‚  â”‚    - Agent stopped                              â”‚   â”‚
â”‚  â”‚    - Agent status                               â”‚   â”‚
â”‚  â”‚    - Session metadata                           â”‚   â”‚
â”‚  â”‚                                                  â”‚   â”‚
â”‚  â”‚  âŒ CANNOT SEE:                                  â”‚   â”‚
â”‚  â”‚    - User speech                                â”‚   â”‚
â”‚  â”‚    - AI responses                               â”‚   â”‚
â”‚  â”‚    - Conversation content                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Summary Table

| Information | Backend | Flutter | Available? |
|------------|---------|---------|------------|
| Agent starts | âœ… Yes | âœ… Yes | Yes |
| Agent stops | âœ… Yes | âœ… Yes | Yes |
| Agent status | âœ… Yes | âœ… Yes | Yes |
| User speaks (audio) | âŒ No | âœ… Yes | Yes |
| User speech (text) | âŒ No | âŒ No | No* |
| AI response (text) | âŒ No | âŒ No | No* |
| AI speaks (audio) | âŒ No | âœ… Yes | Yes |
| Session duration | âœ… Yes | âœ… Yes | Yes |
| Audio quality | âŒ No | âœ… Yes | Yes |

*Unless you implement custom logging or proxy

## Conclusion

**Backend console shows:**
- Agent lifecycle events
- Configuration details
- Status updates

**Flutter console shows:**
- Audio events
- User interactions
- Real-time state changes

**Conversation content:**
- Not available by default
- Happens in Agora RTC channel
- Requires custom implementation to log

For most use cases, monitoring **agent status** (backend) and **audio events** (Flutter) is sufficient.
